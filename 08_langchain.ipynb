{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "be58b994-bc68-4166-91d5-282418b78864",
      "metadata": {
        "id": "be58b994-bc68-4166-91d5-282418b78864"
      },
      "source": [
        "# Project: Langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5120b06-0abf-49e3-b54d-db8afa9eda01",
      "metadata": {
        "id": "c5120b06-0abf-49e3-b54d-db8afa9eda01"
      },
      "source": [
        "**Instructions for Students:**\n",
        "\n",
        "Please carefully follow these steps to complete and submit your project:\n",
        "\n",
        "1. **Make a copy of the Project**: Please make a copy of this project either to your own Google Drive or download locally. Work on the copy of the project. The master project is **Read-Only**, meaning you can edit, but it will not be saved when you close the master project. To avoid total loss of your work, remember to make a copy.\n",
        "\n",
        "2. **Completing the Project**: You are required to work on and complete all tasks in the provided project. Be disciplined and ensure that you thoroughly engage with each task.\n",
        "   \n",
        "3. **Creating a Google Drive Folder**: Each of you must create a new folder on your Google Drive. This will be the repository for all your completed project files, aiding you in keeping your work organized and accessible.\n",
        "   \n",
        "4. **Uploading Completed Project**: Upon completion of your project, make sure to upload all necessary files, involving codes, reports, and related documents into the created Google Drive folder. Save this link in the 'Student Identity' section and also provide it as the last parameter in the `submit` function that has been provided.\n",
        "   \n",
        "5. **Sharing Folder Link**: You're required to share the link to your project Google Drive folder. This is crucial for the submission and evaluation of your project.\n",
        "   \n",
        "6. **Setting Permission to Public**: Please make sure your Google Drive folder is set to public. This allows your instructor to access your solutions and assess your work correctly.\n",
        "\n",
        "Adhering to these procedures will facilitate a smooth project evaluation process for you and the reviewers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eca56111-19cb-46c0-a77b-11bd18c55673",
      "metadata": {
        "id": "eca56111-19cb-46c0-a77b-11bd18c55673"
      },
      "source": [
        "**Description:**\n",
        "\n",
        "Welcome to your project assignment on Langchain. This project will give you hands-on experience and a deeper understanding of the concepts you learned. You will be assigned the following novel `Pride and Prejudice` by Jane Austen:\n",
        "\n",
        "* In text file format (.txt) as your source of data: https://www.gutenberg.org/cache/epub/1342/pg1342.txt\n",
        "* Alternatively you can also use the html version: http://authorama.com/book/pride-and-prejudice.html\n",
        "\n",
        "Your task is to:\n",
        "\n",
        "* Create a chatbot that will receive a user query and get the answer based on the content of the novel.\n",
        "* Create a gradio interface for your chatbot.\n",
        "\n",
        "Remember, the key to mastering these concepts is practice. So, take your time to understand each task, apply your knowledge, and don't hesitate to ask questions if you encounter any difficulties. Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1cfea16-f8bf-4d6e-acf6-68bc94a4651e",
      "metadata": {
        "id": "d1cfea16-f8bf-4d6e-acf6-68bc94a4651e"
      },
      "source": [
        "## Grading Criteria\n",
        "\n",
        "There are 2 criterias for scoring, all have the same weight. Each criteria will give you either 100 point if you are correct and 0 if you are wrong. The final score for the project will the the average of all criterias in this project.\n",
        "\n",
        "* Criteria 1: This task will assess your ability to use langchain to pass a text input, query the LLM and return the result.\n",
        "\n",
        "* Criteria 2: This task will assess your ability to use Gradio as UI (User Interface) and interact with Langchain.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c56269c6-cdf6-452a-ab67-1771dd20e7a9",
      "metadata": {
        "id": "c56269c6-cdf6-452a-ab67-1771dd20e7a9"
      },
      "source": [
        "**Notes:**\n",
        "\n",
        "Please take note of the following important points while working on this project:\n",
        "\n",
        "1. Do not change the Query Space code block, you can make a copy for your own inference.\n",
        "\n",
        "2. Feel free to add new code block to separate your code into manageable blocks.\n",
        "\n",
        "3. We recommend OpenAI or Gemini, a trial version is still available. But if you want to try other LLM, please feel free to do so.\n",
        "\n",
        "4. You do need to pass OPENAI_API_KEY as an environment variable because the Google Colab will be public, there are many methods, but here is one that you may use:\n",
        "   - Install python-dotenv\n",
        "   - Create an env file\n",
        "   - Fill the env file with the key-value pair for OPENAI_API_KEY\n",
        "   - Run the following magic command\n",
        "     - `%load_ext dotenv`\n",
        "     - `%dotenv ./openai.env`\n",
        "   - You can check if the API KEY is available using `os.environ`\n",
        "     - `os.environ['OPENAI_API_KEY']`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "213a611a-c434-4894-ba35-689963ee5274",
      "metadata": {
        "id": "213a611a-c434-4894-ba35-689963ee5274"
      },
      "outputs": [],
      "source": [
        "# @title #### Student Identity\n",
        "student_id = \"REAWBBVN\" # @param {type:\"string\"}\n",
        "name = \"Riofebri Prasetia\" # @param {type:\"string\"}\n",
        "drive_link = \"https://drive.google.com/drive/u/0/folders/1YJaS9kdDtcqwlDiJbHpHL4Uxb3B-02oX\"  # @param {type:\"string\"}\n",
        "assignment_id = \"00_langchain_project\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c97aef3-b747-49f7-99e0-4086c03e4200",
      "metadata": {
        "id": "2c97aef3-b747-49f7-99e0-4086c03e4200"
      },
      "source": [
        "## Installation and Import `rggrader` Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "36c07e23-0280-467f-b0d2-44d966253bb4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36c07e23-0280-467f-b0d2-44d966253bb4",
        "outputId": "e8e3f303-9555-4d48-c0ec-9af845c14689"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rggrader in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.6)\n",
            "Requirement already satisfied: requests in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rggrader) (2.32.3)\n",
            "Requirement already satisfied: pandas in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rggrader) (2.2.3)\n",
            "Requirement already satisfied: Pillow in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rggrader) (10.4.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->rggrader) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from pandas->rggrader) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->rggrader) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->rggrader) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->rggrader) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->rggrader) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->rggrader) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->rggrader) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->rggrader) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install rggrader\n",
        "from rggrader import submit_image\n",
        "from rggrader import submit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4af3420-ff0e-472b-8b44-7a495ddf76c3",
      "metadata": {
        "id": "a4af3420-ff0e-472b-8b44-7a495ddf76c3"
      },
      "source": [
        "## Working Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "aad1982a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: openai==0.28 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.28.0)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: requests>=2.20 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==0.28) (4.66.5)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==0.28) (3.10.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai==0.28) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai==0.28) (1.13.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->openai==0.28) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# %pip install langchain gradio python-dotenv rggrader openai\n",
        "# %pip install langchain_community\n",
        "%pip uninstall openai\n",
        "%pip install openai==0.28\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c1fb239a-1c81-4476-9009-d87abadf9506",
      "metadata": {
        "id": "c1fb239a-1c81-4476-9009-d87abadf9506"
      },
      "outputs": [
        {
          "ename": "RateLimitError",
          "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the full names of the two main characters in Pride and Prejudice?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Menggunakan OpenAI GPT-3.5-turbo dengan ChatCompletion API\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Menampilkan jawaban dari API\u001b[39;00m\n\u001b[0;32m     30\u001b[0m answer \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    763\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    767\u001b[0m     )\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
          ]
        }
      ],
      "source": [
        "import openai\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Memuat API key dari file .env\n",
        "load_dotenv(\".env\")\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Menggunakan Langchain untuk memuat GPT-3.5-Turbo\n",
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(model_name=\"gpt-3.5-turbo\")  # Ganti model menjadi gpt-3.5-turbo\n",
        "\n",
        "qa = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "# Memuat teks novel\n",
        "with open(\"pg1342.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    novel_text = file.read()\n",
        "\n",
        "# Membuat objek Document\n",
        "document = Document(page_content=novel_text)\n",
        "\n",
        "# Mengajukan pertanyaan menggunakan Langchain\n",
        "query = \"What are the full names of the two main characters in Pride and Prejudice?\"\n",
        "\n",
        "# Menggunakan input_documents\n",
        "answer = qa.run(input_documents=[document], question=query)\n",
        "\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc8d6a4a-e296-4540-92ff-c813131a4e41",
      "metadata": {
        "id": "fc8d6a4a-e296-4540-92ff-c813131a4e41"
      },
      "source": [
        "## Query Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2acc62c3-a773-4761-951c-fbf8ead87261",
      "metadata": {
        "id": "2acc62c3-a773-4761-951c-fbf8ead87261"
      },
      "outputs": [],
      "source": [
        "query = \"What are the full names of the two main characters in Pride and Prejudice ?\"\n",
        "answer = qa.run(query)\n",
        "\n",
        "question_id = \"00_langchain_query_answer\"\n",
        "submit(student_id, name, assignment_id, str(answer), question_id, drive_link)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b151c52-20a3-432f-ab16-4721c16581c4",
      "metadata": {
        "id": "2b151c52-20a3-432f-ab16-4721c16581c4"
      },
      "source": [
        "## Submit Gradio screenshot\n",
        "\n",
        "![Upload colab](https://storage.googleapis.com/rg-ai-bootcamp/project-3-pipeline-and-gradio/upload-colab.png)\n",
        "\n",
        "You need to submit screenshot of your Gradio's app. In Google Colab you can just use the \"Folder\" sidebar and click the upload button.\n",
        "\n",
        "Make sure your screenshot match below requirements:\n",
        "\n",
        "- It should have an input box for user to type the query and an output box for user to type the query.\n",
        "- It should have the query and the answer from Query Space block in the respective boxes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce55a43f-9af3-47ee-8b76-2a6597159635",
      "metadata": {
        "id": "ce55a43f-9af3-47ee-8b76-2a6597159635"
      },
      "source": [
        "Example of Expected Output:\n",
        "\n",
        "![gradio-result](https://storage.googleapis.com/rg-ai-bootcamp/projects/langchain-gradio.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d025e7e-e51c-4194-ba0e-1eb83cc92315",
      "metadata": {
        "id": "8d025e7e-e51c-4194-ba0e-1eb83cc92315"
      },
      "outputs": [],
      "source": [
        "#write your Gradio implementation here\n",
        "import gradio as gr\n",
        "\n",
        "def chatbot(query):\n",
        "    return qa.run(query, documents=[novel_text])\n",
        "\n",
        "# Membuat antarmuka Gradio\n",
        "interface = gr.Interface(fn=chatbot, inputs=\"text\", outputs=\"text\", title=\"Pride and Prejudice Chatbot\")\n",
        "interface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ced6b581-708f-4758-86ff-3cd51bf14f99",
      "metadata": {
        "id": "ced6b581-708f-4758-86ff-3cd51bf14f99"
      },
      "outputs": [],
      "source": [
        "question_id = \"01_langchain_gradio\"\n",
        "submit_image(student_id, question_id, './submission.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "792aa177-c74e-42e5-9881-40376cd746a8",
      "metadata": {
        "id": "792aa177-c74e-42e5-9881-40376cd746a8"
      },
      "source": [
        "# FIN"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
